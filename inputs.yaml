# TODO the data might not be balanced in which case we 
# cannot just choose the first 1000 examples, perhaps we should 
# take extra care here and balance the data first and load 
# only a portion of each class.
# Number of examples, set to None if want to load all
m_train : 1000 # number of examples for training
m_test  : 100 # number of examples for testing
m_valid : 100 # number of examples for validation

# Training hyperparameters
n_epochs : 50 # int: number of epochs
lr       : 0.01 # float: initial learning rate
device   : 'cpu' # str: which device to use 'cpu' or ''

# DataLoader options
<<<<<<< HEAD
batch_size  : 1000 # int: batch size
=======
batch_size  : 50 # int: batch size
>>>>>>> 2a8c80965488291685078938fd4b41a8e2e3f115
shuffle     : True # Do you want to shuffle the data after each epoch?
num_workers : 4 # number of workers for DataLoader

# Scheduler options 
# The scheduler controls the learning rate during training, if it
# detects that the training loss is not changing for some period of time
# it will reduce the learning rate by some factor
factor    : 0.5 # float: learning rate multiplier
patience  : 4 # int: how many epochs to wait
threshold : 0.001 # float: if loss hasn't changed by more than this val.

# TODO this is not functional, make this functional
# Seed for training, this option lets you control the seed from which to
# start the model each time rather than letting the starting point be
# random each time, this can be used for testing the effect of different
# hyperparameters
use_seed : True # bool: option if we should use a seed or not
seed     : 0 # int: choose seed value

# Model choice, options:
# ['Linear', 'smallLinear', 'normLinear', 'convNet']
model : 'Linear' # str: model to use for training

# Loss function, options:
# ['BCELoss']
loss : 'BCELoss' # str: choose the loss function to use
